{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9a4981-0132-4fbc-8882-5e1ff6d70345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.yandex-team.ru/simple/\n",
      "Collecting tensorflow\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/tensorflow/1280594/tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 479.6 MB 59.2 MB/s eta 0:00:01    |██▉                             | 43.1 MB 35.6 MB/s eta 0:00:13     |█████▋                          | 84.5 MB 43.4 MB/s eta 0:00:10     |██████████▎                     | 154.1 MB 50.2 MB/s eta 0:00:07     |██████████████████▋             | 279.2 MB 47.4 MB/s eta 0:00:05     |█████████████████████           | 313.9 MB 34.1 MB/s eta 0:00:05     |████████████████████████████    | 420.5 MB 60.0 MB/s eta 0:00:01     |██████████████████████████████▊ | 461.3 MB 59.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/termcolor/1320427/termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/wrapt/1307914/wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 21.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/astunparse/441456/astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/google-pasta/469158/google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 37.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in ./venv/lib/python3.8/site-packages (from tensorflow) (44.0.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/opt-einsum/521113/opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 44.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/tensorflow-estimator/1223565/tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[K     |████████████████████████████████| 440 kB 27.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers>=23.1.21\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/flatbuffers/1208672/flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/grpcio/1351475/grpcio-1.60.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.4 MB 46.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/gast/533064/gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting numpy<=1.24.3,>=1.22\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/numpy/1192767/numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 39.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/absl-py/1342882/absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 40.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/h5py/1289663/h5py-3.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8 MB 31.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/libclang/1237574/libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.9 MB 40.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\"\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/tensorflow-io-gcs-filesystem/1270461/tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 31.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.14,>=2.13.1\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/Keras/1223235/keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 40.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.14,>=2.13\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/tensorboard/1199103/tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 49.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions<4.6.0,>=3.6.6\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/typing-extensions/1156775/typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.8/site-packages (from tensorflow) (23.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/protobuf/1340352/protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 47.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel<1.0,>=0.23.0\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/wheel/1317113/wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 35.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/Werkzeug/1297332/werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[K     |████████████████████████████████| 226 kB 30.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/google-auth/1347269/google_auth-2.27.0-py2.py3-none-any.whl (186 kB)\n",
      "\u001b[K     |████████████████████████████████| 186 kB 39.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/google-auth-oauthlib/1153282/google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/tensorboard-data-server/1297068/tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/Markdown/1340157/Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 55.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/cachetools/1297522/cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/pyasn1-modules/1191887/pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 41.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/rsa/1056658/rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/requests-oauthlib/940222/requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in ./venv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (7.0.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3.2)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/pyasn1/1314678/pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 38.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/oauthlib/1094958/oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 33.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in ./venv/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.17.0)\n",
      "Installing collected packages: termcolor, wrapt, wheel, astunparse, google-pasta, numpy, opt-einsum, tensorflow-estimator, flatbuffers, grpcio, gast, absl-py, h5py, libclang, tensorflow-io-gcs-filesystem, keras, werkzeug, protobuf, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-data-server, markdown, tensorboard, typing-extensions, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.9.0\n",
      "    Uninstalling typing-extensions-4.9.0:\n",
      "      Successfully uninstalled typing-extensions-4.9.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.27.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.60.1 h5py-3.10.0 keras-2.13.1 libclang-16.0.6 markdown-3.5.2 numpy-1.24.3 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.25.2 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.4.0 typing-extensions-4.5.0 werkzeug-3.0.1 wheel-0.42.0 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260be347",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "# import tensorflow as tf\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='https://storage.yandexcloud.net',\n",
    "    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    ")\n",
    "BUCKET_NAME = 'tnn-hse-medtech'\n",
    "DATASET_DIR = 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03993362",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('normalized_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6cbdc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expert</th>\n",
       "      <th>file_id</th>\n",
       "      <th>severity</th>\n",
       "      <th>relative_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MedicalExpert-I</td>\n",
       "      <td>c7284c66fa8ec0ab4594e5dcd44866f408238f685e999e...</td>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (1).png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MedicalExpert-I</td>\n",
       "      <td>4a547b94fe02a7565beb21aa9195f4deffe831086da240...</td>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (10).png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MedicalExpert-I</td>\n",
       "      <td>ca8a296d1e15e0ed84c1ab82440426f28cd0582c19964f...</td>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (100).png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MedicalExpert-I</td>\n",
       "      <td>6f8bb6bbf0f4def4fdbe1a486064e47eefed0fa832246c...</td>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (101).png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MedicalExpert-I</td>\n",
       "      <td>d3c8f051ee6c5f59dff4657b7c007860be652e313d85ab...</td>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (102).png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>MedicalExpert-II</td>\n",
       "      <td>a762fc9fda75a15538789eb78b53a7ca12631e3c59993d...</td>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (95).png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>MedicalExpert-II</td>\n",
       "      <td>0ab9e6787dd93e3ad8505c6dcbafa955b91554b026c014...</td>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (96).png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>MedicalExpert-II</td>\n",
       "      <td>1b3dba34278b1ba238c7051be6886cab2cc2c1c985d368...</td>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (97).png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>MedicalExpert-II</td>\n",
       "      <td>3338d1a673dd92b49fc1967f0f3cea6bc645fea48bb84b...</td>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (98).png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>MedicalExpert-II</td>\n",
       "      <td>8bf89927b1adc0b27fde55d015cd285cf6be47099a31b9...</td>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (99).png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3278 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                expert                                            file_id  \\\n",
       "0      MedicalExpert-I  c7284c66fa8ec0ab4594e5dcd44866f408238f685e999e...   \n",
       "1      MedicalExpert-I  4a547b94fe02a7565beb21aa9195f4deffe831086da240...   \n",
       "2      MedicalExpert-I  ca8a296d1e15e0ed84c1ab82440426f28cd0582c19964f...   \n",
       "3      MedicalExpert-I  6f8bb6bbf0f4def4fdbe1a486064e47eefed0fa832246c...   \n",
       "4      MedicalExpert-I  d3c8f051ee6c5f59dff4657b7c007860be652e313d85ab...   \n",
       "...                ...                                                ...   \n",
       "3273  MedicalExpert-II  a762fc9fda75a15538789eb78b53a7ca12631e3c59993d...   \n",
       "3274  MedicalExpert-II  0ab9e6787dd93e3ad8505c6dcbafa955b91554b026c014...   \n",
       "3275  MedicalExpert-II  1b3dba34278b1ba238c7051be6886cab2cc2c1c985d368...   \n",
       "3276  MedicalExpert-II  3338d1a673dd92b49fc1967f0f3cea6bc645fea48bb84b...   \n",
       "3277  MedicalExpert-II  8bf89927b1adc0b27fde55d015cd285cf6be47099a31b9...   \n",
       "\n",
       "      severity                               relative_path  \n",
       "0            0    MedicalExpert-I/0Normal/NormalG0 (1).png  \n",
       "1            0   MedicalExpert-I/0Normal/NormalG0 (10).png  \n",
       "2            0  MedicalExpert-I/0Normal/NormalG0 (100).png  \n",
       "3            0  MedicalExpert-I/0Normal/NormalG0 (101).png  \n",
       "4            0  MedicalExpert-I/0Normal/NormalG0 (102).png  \n",
       "...        ...                                         ...  \n",
       "3273         4  MedicalExpert-II/4Severe/SevereG4 (95).png  \n",
       "3274         4  MedicalExpert-II/4Severe/SevereG4 (96).png  \n",
       "3275         4  MedicalExpert-II/4Severe/SevereG4 (97).png  \n",
       "3276         4  MedicalExpert-II/4Severe/SevereG4 (98).png  \n",
       "3277         4  MedicalExpert-II/4Severe/SevereG4 (99).png  \n",
       "\n",
       "[3278 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e5ff8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0ms3_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mBucket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mKey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mExtraArgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mCallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mConfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Download an S3 object to a file.\n",
      "\n",
      "Usage::\n",
      "\n",
      "    import boto3\n",
      "    s3 = boto3.resource('s3')\n",
      "    s3.meta.client.download_file('mybucket', 'hello.txt', '/tmp/hello.txt')\n",
      "\n",
      "Similar behavior as S3Transfer's download_file() method,\n",
      "except that parameters are capitalized. Detailed examples can be found at\n",
      ":ref:`S3Transfer's Usage <ref_s3transfer_usage>`.\n",
      "\n",
      ":type Bucket: str\n",
      ":param Bucket: The name of the bucket to download from.\n",
      "\n",
      ":type Key: str\n",
      ":param Key: The name of the key to download from.\n",
      "\n",
      ":type Filename: str\n",
      ":param Filename: The path to the file to download to.\n",
      "\n",
      ":type ExtraArgs: dict\n",
      ":param ExtraArgs: Extra arguments that may be passed to the\n",
      "    client operation. For allowed download arguments see\n",
      "    boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n",
      "\n",
      ":type Callback: function\n",
      ":param Callback: A method which takes a number of bytes transferred to\n",
      "    be periodically called during the download.\n",
      "\n",
      ":type Config: boto3.s3.transfer.TransferConfig\n",
      ":param Config: The transfer configuration to be used when performing the\n",
      "    transfer.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/boto3/s3/inject.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "s3_client.download_file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70edf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efd7644e6b343a78ff8da63740adc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.notebook import tqdm\n",
    "import PIL\n",
    "\n",
    "IMAGE_DIRECTORY = Path('.') / 'images'\n",
    "\n",
    "@dataclass()\n",
    "class Metadata:\n",
    "    severity: int\n",
    "    relative_path: str\n",
    "    path: Path\n",
    "    width: int\n",
    "    height: int\n",
    "    size: int\n",
    "\n",
    "def handle_file(item) -> Metadata:\n",
    "    path = IMAGE_DIRECTORY / item.relative_path\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    s3_client.download_file(BUCKET_NAME, f'{DATASET_DIR}{item.relative_path}', path)\n",
    "    with PIL.Image.open(str(path)) as im:\n",
    "        width, height = im.size\n",
    "    return Metadata(item.severity, item.relative_path, path, width, height, size=path.stat().st_size)\n",
    "\n",
    "raw_data = []\n",
    "with ThreadPoolExecutor(max_workers=100) as pool:\n",
    "    for item in tqdm(pool.map(handle_file, data.itertuples(), chunksize=1), total=len(data)):\n",
    "        raw_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "638ccbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severity</th>\n",
       "      <th>relative_path</th>\n",
       "      <th>path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (1).png</td>\n",
       "      <td>images/MedicalExpert-I/0Normal/NormalG0 (1).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>31193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (10).png</td>\n",
       "      <td>images/MedicalExpert-I/0Normal/NormalG0 (10).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>34614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (100).png</td>\n",
       "      <td>images/MedicalExpert-I/0Normal/NormalG0 (100).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>33982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (101).png</td>\n",
       "      <td>images/MedicalExpert-I/0Normal/NormalG0 (101).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>28115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (102).png</td>\n",
       "      <td>images/MedicalExpert-I/0Normal/NormalG0 (102).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>31167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (95).png</td>\n",
       "      <td>images/MedicalExpert-II/4Severe/SevereG4 (95).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>28841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (96).png</td>\n",
       "      <td>images/MedicalExpert-II/4Severe/SevereG4 (96).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>32913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (97).png</td>\n",
       "      <td>images/MedicalExpert-II/4Severe/SevereG4 (97).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>34643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (98).png</td>\n",
       "      <td>images/MedicalExpert-II/4Severe/SevereG4 (98).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>30874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (99).png</td>\n",
       "      <td>images/MedicalExpert-II/4Severe/SevereG4 (99).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>35121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3278 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      severity                               relative_path  \\\n",
       "0            0    MedicalExpert-I/0Normal/NormalG0 (1).png   \n",
       "1            0   MedicalExpert-I/0Normal/NormalG0 (10).png   \n",
       "2            0  MedicalExpert-I/0Normal/NormalG0 (100).png   \n",
       "3            0  MedicalExpert-I/0Normal/NormalG0 (101).png   \n",
       "4            0  MedicalExpert-I/0Normal/NormalG0 (102).png   \n",
       "...        ...                                         ...   \n",
       "3273         4  MedicalExpert-II/4Severe/SevereG4 (95).png   \n",
       "3274         4  MedicalExpert-II/4Severe/SevereG4 (96).png   \n",
       "3275         4  MedicalExpert-II/4Severe/SevereG4 (97).png   \n",
       "3276         4  MedicalExpert-II/4Severe/SevereG4 (98).png   \n",
       "3277         4  MedicalExpert-II/4Severe/SevereG4 (99).png   \n",
       "\n",
       "                                                   path  width  height   size  \n",
       "0       images/MedicalExpert-I/0Normal/NormalG0 (1).png    300     162  31193  \n",
       "1      images/MedicalExpert-I/0Normal/NormalG0 (10).png    300     162  34614  \n",
       "2     images/MedicalExpert-I/0Normal/NormalG0 (100).png    300     162  33982  \n",
       "3     images/MedicalExpert-I/0Normal/NormalG0 (101).png    300     162  28115  \n",
       "4     images/MedicalExpert-I/0Normal/NormalG0 (102).png    300     162  31167  \n",
       "...                                                 ...    ...     ...    ...  \n",
       "3273  images/MedicalExpert-II/4Severe/SevereG4 (95).png    300     162  28841  \n",
       "3274  images/MedicalExpert-II/4Severe/SevereG4 (96).png    300     162  32913  \n",
       "3275  images/MedicalExpert-II/4Severe/SevereG4 (97).png    300     162  34643  \n",
       "3276  images/MedicalExpert-II/4Severe/SevereG4 (98).png    300     162  30874  \n",
       "3277  images/MedicalExpert-II/4Severe/SevereG4 (99).png    300     162  35121  \n",
       "\n",
       "[3278 rows x 6 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(raw_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "69bf51a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "width  height\n",
       "300    162       2916\n",
       "640    161        362\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['width', 'height']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ad80f19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severity</th>\n",
       "      <th>relative_path</th>\n",
       "      <th>path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (1).png</td>\n",
       "      <td>images/MedicalExpert-I/0Normal/NormalG0 (1).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>31193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (10).png</td>\n",
       "      <td>images/MedicalExpert-I/0Normal/NormalG0 (10).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>34614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (100).png</td>\n",
       "      <td>images/MedicalExpert-I/0Normal/NormalG0 (100).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>33982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (101).png</td>\n",
       "      <td>images/MedicalExpert-I/0Normal/NormalG0 (101).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>28115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>MedicalExpert-I/0Normal/NormalG0 (102).png</td>\n",
       "      <td>images/MedicalExpert-I/0Normal/NormalG0 (102).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>31167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (95).png</td>\n",
       "      <td>images/MedicalExpert-II/4Severe/SevereG4 (95).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>28841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (96).png</td>\n",
       "      <td>images/MedicalExpert-II/4Severe/SevereG4 (96).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>32913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (97).png</td>\n",
       "      <td>images/MedicalExpert-II/4Severe/SevereG4 (97).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>34643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (98).png</td>\n",
       "      <td>images/MedicalExpert-II/4Severe/SevereG4 (98).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>30874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>4</td>\n",
       "      <td>MedicalExpert-II/4Severe/SevereG4 (99).png</td>\n",
       "      <td>images/MedicalExpert-II/4Severe/SevereG4 (99).png</td>\n",
       "      <td>300</td>\n",
       "      <td>162</td>\n",
       "      <td>35121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2916 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      severity                               relative_path  \\\n",
       "0            0    MedicalExpert-I/0Normal/NormalG0 (1).png   \n",
       "1            0   MedicalExpert-I/0Normal/NormalG0 (10).png   \n",
       "2            0  MedicalExpert-I/0Normal/NormalG0 (100).png   \n",
       "3            0  MedicalExpert-I/0Normal/NormalG0 (101).png   \n",
       "4            0  MedicalExpert-I/0Normal/NormalG0 (102).png   \n",
       "...        ...                                         ...   \n",
       "3273         4  MedicalExpert-II/4Severe/SevereG4 (95).png   \n",
       "3274         4  MedicalExpert-II/4Severe/SevereG4 (96).png   \n",
       "3275         4  MedicalExpert-II/4Severe/SevereG4 (97).png   \n",
       "3276         4  MedicalExpert-II/4Severe/SevereG4 (98).png   \n",
       "3277         4  MedicalExpert-II/4Severe/SevereG4 (99).png   \n",
       "\n",
       "                                                   path  width  height   size  \n",
       "0       images/MedicalExpert-I/0Normal/NormalG0 (1).png    300     162  31193  \n",
       "1      images/MedicalExpert-I/0Normal/NormalG0 (10).png    300     162  34614  \n",
       "2     images/MedicalExpert-I/0Normal/NormalG0 (100).png    300     162  33982  \n",
       "3     images/MedicalExpert-I/0Normal/NormalG0 (101).png    300     162  28115  \n",
       "4     images/MedicalExpert-I/0Normal/NormalG0 (102).png    300     162  31167  \n",
       "...                                                 ...    ...     ...    ...  \n",
       "3273  images/MedicalExpert-II/4Severe/SevereG4 (95).png    300     162  28841  \n",
       "3274  images/MedicalExpert-II/4Severe/SevereG4 (96).png    300     162  32913  \n",
       "3275  images/MedicalExpert-II/4Severe/SevereG4 (97).png    300     162  34643  \n",
       "3276  images/MedicalExpert-II/4Severe/SevereG4 (98).png    300     162  30874  \n",
       "3277  images/MedicalExpert-II/4Severe/SevereG4 (99).png    300     162  35121  \n",
       "\n",
       "[2916 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double = df[df.width == 640]\n",
    "single = df[df.width == 300]\n",
    "single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "63c83e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2333 validated image filenames belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 583 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# classes = np.asarray(map(str, range(5))).reshape((-1, 1))\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "training_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=single, \n",
    "    directory=IMAGE_DIRECTORY,\n",
    "    x_col='relative_path',\n",
    "    y_col='severity',\n",
    "    target_size=(300, 162),\n",
    "    # classes=classes,\n",
    "    # classes=['0', '1', '2', '3', '4'],\n",
    "    # class_mode='categorical',\n",
    "    interpolation='bicubic',\n",
    "    subset='training',\n",
    "    batch_size=128,\n",
    ")\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=single, \n",
    "    directory=IMAGE_DIRECTORY,\n",
    "    x_col='relative_path',\n",
    "    y_col='severity',\n",
    "    target_size=(300, 162),\n",
    "    # classes=classes,\n",
    "    # classes=['0', '1', '2', '3', '4'],\n",
    "    # class_mode='categorical',\n",
    "    interpolation='bicubic',\n",
    "    subset='validation',\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "12802011-3234-4c97-bc23-1b31632c3818",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, None, None, 3) vs (None, None)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m ConvolutionalAutoEncoder()\n\u001b[1;32m     27\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/training.py:2810\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2799\u001b[0m \n\u001b[1;32m   2800\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2806\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2808\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2809\u001b[0m )\n\u001b[0;32m-> 2810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2812\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2822\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2824\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2825\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/tmp/__autograph_generated_fileuodiyfd6.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/home/tiunovnn/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, None, None, 3) vs (None, None)).\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Model, Sequential\n",
    "\n",
    "class ConvolutionalAutoEncoder(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Sequential([\n",
    "            layers.Input(shape=(300, 162, 3), name='e1'),\n",
    "            # layers.Flatten(name='e2'),\n",
    "            layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2, name='e3'),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2, name='e4'),\n",
    "        ], name='encoder')\n",
    "        self.decoder = Sequential([\n",
    "            layers.Conv2DTranspose(8, kernel_size=(3, 3), strides=2, activation='relu', padding='same', name='d1', output_padding=1),\n",
    "            layers.Conv2DTranspose(16, kernel_size=(3, 3), strides=2, activation='relu', padding='same', name='d2', output_padding=1),\n",
    "            # layers.GlobalAveragePooling2D(keepdims=True, name='d3'),\n",
    "            layers.Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same', name='d4'),\n",
    "        ], name='decoder')\n",
    "\n",
    "    def call(self, x):\n",
    "        latent_x = self.encoder(x)\n",
    "        decoded_x = self.decoder(latent_x)\n",
    "        return decoded_x\n",
    "\n",
    "    \n",
    "autoencoder = ConvolutionalAutoEncoder()\n",
    "autoencoder.compile(optimizer='adam', loss='bce')\n",
    "autoencoder.fit_generator(training_generator, epochs=1000)\n",
    "autoencoder.encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0572067d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must provide an `input_shape` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/hse-knee-xray-research/models/ML/venv/lib/python3.8/site-packages/keras/src/engine/sequential.py:378\u001b[0m, in \u001b[0;36mSequential.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must provide an `input_shape` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_graph_network_for_inferred_shape(input_shape)\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n",
      "\u001b[0;31mValueError\u001b[0m: You must provide an `input_shape` argument."
     ]
    }
   ],
   "source": [
    "autoencoder.decoder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b3afb2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.2.0%2Bcpu-cp38-cp38-linux_x86_64.whl (186.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 186.7 MB 7.5 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.17.0%2Bcpu-cp38-cp38-linux_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=4.8.0\n",
      "  Downloading https://download.pytorch.org/whl/typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting filelock\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Collecting sympy\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 66.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 69.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx in ./venv/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.8/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.8/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.8/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 61.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.8/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.8/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.8/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.8/site-packages (from requests->torchvision) (3.6)\n",
      "\u001b[31mERROR: tensorflow 2.13.1 has requirement typing-extensions<4.6.0,>=3.6.6, but you'll have typing-extensions 4.8.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: typing-extensions, filelock, mpmath, sympy, fsspec, torch, torchvision\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.5.0\n",
      "    Uninstalling typing-extensions-4.5.0:\n",
      "      Successfully uninstalled typing-extensions-4.5.0\n",
      "Successfully installed filelock-3.9.0 fsspec-2023.4.0 mpmath-1.3.0 sympy-1.12 torch-2.2.0+cpu torchvision-0.17.0+cpu typing-extensions-4.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48917201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.yandex-team.ru/simple/\n",
      "Collecting torchsummary\n",
      "  Downloading https://pypi.yandex-team.ru/repo/default/download/torchsummary/435801/torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "13791f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "SINGLE_PATH = Path('.') / 'single'\n",
    "# for item in single.itertuples():\n",
    "#     directory = SINGLE_PATH / str(item.severity)\n",
    "#     directory.mkdir(parents=True, exist_ok=True)\n",
    "#     new_path =  directory / Path(item.path.name)\n",
    "#     Path(item.path).rename(new_path)\n",
    "\n",
    "train_transforms = transforms.Compose([#transforms.RandomRotation(30),\n",
    "                                      #transforms.RandomResizedCrop(224),\n",
    "                                      #transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor()])\n",
    "dataset = ImageFolder(SINGLE_PATH, transform=train_transforms)\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52fed7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(0.8275)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(dataset_loader)\n",
    "images, labels = next(dataiter)\n",
    "print(torch.min(images), torch.max(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1950213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchConvAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, stride=2, padding=1), # -> N, 16, 150, 81\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), # -> N, 32, 75, 41\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), # -> N, 64, 38, 21\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1), # -> N, 128, 19, 11\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1), # -> N, 256, 10, 6\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, (6, 10)), # -> N, 512, 1, 1\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, (6, 10)), # -> N, 256, 10, 6\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=0), # -> N, 128, 19, 11\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=[0, 1]), # -> N, 64, 38, 21\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=0), # -> N, 32, 75, 41\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=[0, 1]), # -> N, 16, 150, 81\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, 3, stride=2, padding=1, output_padding=1), # -> N, 1, 300, 162\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a29a7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TorchConvAutoEncoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65c59b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 16, 81, 150]             448\n",
      "              ReLU-2          [-1, 16, 81, 150]               0\n",
      "            Conv2d-3           [-1, 32, 41, 75]           4,640\n",
      "              ReLU-4           [-1, 32, 41, 75]               0\n",
      "            Conv2d-5           [-1, 64, 21, 38]          18,496\n",
      "              ReLU-6           [-1, 64, 21, 38]               0\n",
      "            Conv2d-7          [-1, 128, 11, 19]          73,856\n",
      "              ReLU-8          [-1, 128, 11, 19]               0\n",
      "            Conv2d-9           [-1, 256, 6, 10]         295,168\n",
      "             ReLU-10           [-1, 256, 6, 10]               0\n",
      "           Conv2d-11            [-1, 512, 1, 1]       7,864,832\n",
      "================================================================\n",
      "Total params: 8,257,440\n",
      "Trainable params: 8,257,440\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.56\n",
      "Forward/backward pass size (MB): 5.89\n",
      "Params size (MB): 31.50\n",
      "Estimated Total Size (MB): 37.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model.encoder, (3, 162, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d65e2442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1           [-1, 256, 6, 10]       7,864,576\n",
      "              ReLU-2           [-1, 256, 6, 10]               0\n",
      "   ConvTranspose2d-3          [-1, 128, 11, 19]         295,040\n",
      "              ReLU-4          [-1, 128, 11, 19]               0\n",
      "   ConvTranspose2d-5           [-1, 64, 21, 38]          73,792\n",
      "              ReLU-6           [-1, 64, 21, 38]               0\n",
      "   ConvTranspose2d-7           [-1, 32, 41, 75]          18,464\n",
      "              ReLU-8           [-1, 32, 41, 75]               0\n",
      "   ConvTranspose2d-9          [-1, 16, 81, 150]           4,624\n",
      "             ReLU-10          [-1, 16, 81, 150]               0\n",
      "  ConvTranspose2d-11          [-1, 3, 162, 300]             435\n",
      "================================================================\n",
      "Total params: 8,256,931\n",
      "Trainable params: 8,256,931\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 7.00\n",
      "Params size (MB): 31.50\n",
      "Estimated Total Size (MB): 38.50\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.decoder, (512, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "163b5ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c8b054c7df4c7cb07020c777af6d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/460 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "num_epochs = 10\n",
    "outputs = []\n",
    "with tqdm(total=num_epochs*len(dataset_loader)) as pbar:\n",
    "    for epoch in range(num_epochs):\n",
    "        for img, _ in dataset_loader:\n",
    "            recon = model(img)\n",
    "            loss = criterion(recon, img)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {loss.item():.4f}')\n",
    "    outputs.append((epoch, img, recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f29961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
